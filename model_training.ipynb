{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions API, the model training part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset and taking a look on how the data looks like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  recency_7  frequency_7  monetary_value_7  frequency_30  \\\n",
      "0          1          1            1               8.5             1   \n",
      "1          2          1            1              16.3             1   \n",
      "2          3          1            1               5.6             1   \n",
      "3          4          1            1              32.0             1   \n",
      "4          5          1            1              63.6             1   \n",
      "...      ...        ...          ...               ...           ...   \n",
      "72753  72754          4            2              32.7             2   \n",
      "72754  72755          1            2              58.6             2   \n",
      "72755  72756          2            6              89.9             6   \n",
      "72756  72757          1            1              25.5             1   \n",
      "72757  72758          1            1              18.8             1   \n",
      "\n",
      "       monetary_value_30  \n",
      "0                    8.5  \n",
      "1                   16.3  \n",
      "2                    5.6  \n",
      "3                   32.0  \n",
      "4                   63.6  \n",
      "...                  ...  \n",
      "72753               32.7  \n",
      "72754               58.6  \n",
      "72755               89.9  \n",
      "72756               25.5  \n",
      "72757               18.8  \n",
      "\n",
      "[72758 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn import model_selection\n",
    "import pickle\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "database = \"database.sqlite\"\n",
    "\n",
    "conn = sqlite3.connect(database)\n",
    "\n",
    "data = pd.read_sql(\"select * from passenger_activity_after_registration\", con=conn)\n",
    "print(data)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the data is not huge, I will proceed with Pandas in model training and not use Spark for ex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72758, 6)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>recency_7</th>\n",
       "      <th>frequency_7</th>\n",
       "      <th>monetary_value_7</th>\n",
       "      <th>frequency_30</th>\n",
       "      <th>monetary_value_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.6</td>\n",
       "      <td>1</td>\n",
       "      <td>63.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  recency_7  frequency_7  monetary_value_7  frequency_30  \\\n",
       "0   1          1            1               8.5             1   \n",
       "1   2          1            1              16.3             1   \n",
       "2   3          1            1               5.6             1   \n",
       "3   4          1            1              32.0             1   \n",
       "4   5          1            1              63.6             1   \n",
       "\n",
       "   monetary_value_30  \n",
       "0                8.5  \n",
       "1               16.3  \n",
       "2                5.6  \n",
       "3               32.0  \n",
       "4               63.6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing passenger_id as it will not be of any use in modelling the data, also will remove frequency_30 because it is future knowledge that shouldn't be available before prediction and it is related to 'monetary_value_30' which we will want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'frequency_30'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recency_7              int64\n",
       "frequency_7            int64\n",
       "monetary_value_7     float64\n",
       "monetary_value_30    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    45525\n",
       "2    11409\n",
       "3     4719\n",
       "4     3168\n",
       "7     2958\n",
       "5     2566\n",
       "6     2413\n",
       "Name: recency_7, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['recency_7'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We know already from the feature description that recency_7 is a categorical feature, so let's go ahead and convert it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data['recency_7'] = data.recency_7.astype('category')\n",
    "except Exception as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that recency_7 has been converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us check now for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recency_7            False\n",
       "frequency_7          False\n",
       "monetary_value_7     False\n",
       "monetary_value_30    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No missing values, great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we check each column has wrong enteries. As we know, all columns shouldn't have negative values, as they are frequency or money"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- recency_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### already checked when converting to categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- frequency_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.frequency_7<0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - monetary_value_7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.monetary_value_7<0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- monetary_value_30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.monetary_value_30<0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So all columns are already clean with no missing and no wrong enteries that we can detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to calculate correlation between features to analyze and select suitable features. \n",
    "### Since we have categorical and numerical features, I used pearson correlation in case we are correlation two numerical features, and used cramers for correlating two categorical features (not my code - not used here) and finally eta for correlating numerical features with categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import seaborn as sns\n",
    "\n",
    "def cramers_v(confusion_matrix):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher,\n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "def eta__correlation_ratio(categories, measurements):\n",
    "    fcat, _ = pd.factorize(categories)\n",
    "    cat_num = np.max(fcat)+1\n",
    "    y_avg_array = np.zeros(cat_num)\n",
    "    n_array = np.zeros(cat_num)\n",
    "    for i in range(0,cat_num):\n",
    "        cat_measures = measurements.iloc[np.argwhere(fcat == i).flatten()].values\n",
    "        n_array[i] = len(cat_measures)\n",
    "        y_avg_array[i] = np.average(cat_measures)\n",
    "    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
    "    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
    "    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
    "    if numerator == 0:\n",
    "        eta = 0.0\n",
    "    else:\n",
    "        eta = np.sqrt(numerator/denominator)\n",
    "    return eta\n",
    "\n",
    "corr_matrix = pd.DataFrame(np.nan, index=data.columns, columns=data.columns)\n",
    "for row in corr_matrix.index:\n",
    "    for col in corr_matrix.columns:\n",
    "        if \"category\" in data.dtypes[row].name and \"category\" in data.dtypes[col].name:\n",
    "            #cramers_v category correlation\n",
    "            confusion_matrix = pd.crosstab(data[row], data[col]).values\n",
    "            corr_matrix[col][row] = cramers_v(confusion_matrix)\n",
    "        elif \"category\" in data.dtypes[row].name:\n",
    "            #eta category-numerical correlation\n",
    "            corr_matrix[col][row] = eta__correlation_ratio(data[row].tolist(), data[col])\n",
    "        elif \"category\" in data.dtypes[col].name:\n",
    "            #eta category-numerical correlation\n",
    "            corr_matrix[col][row] = eta__correlation_ratio(data[col].tolist(), data[row])\n",
    "        else:\n",
    "            #pearson correlation for numerical-numerical coorelation\n",
    "            corr_matrix[col][row] = data[row].corr(data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the correaltion matrix using a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sn.heatmap(corr_matrix, annot=True)\n",
    "b, t = plt.ylim()\n",
    "b += 0.5\n",
    "t -= 0.5\n",
    "plt.ylim(b, t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As expected, monetary_value_7 is highly correlated to monetary_value_30, because intuitevly most of the customers having high usages in 7 days would have high usages in 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A fast outlier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Boxplot for monetary_value_30')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,10))\n",
    "\n",
    "sn.boxplot(data=data[['frequency_7']], ax=axs[0])\n",
    "axs[0].set(title=\"Boxplot for frequency_7\")\n",
    "\n",
    "sn.boxplot(data=data[['monetary_value_7']], ax=axs[1])\n",
    "axs[1].set(title=\"Boxplot for monetary_value_7\")\n",
    "\n",
    "sn.boxplot(data=data[['monetary_value_30']], ax=axs[2])\n",
    "axs[2].set(title=\"Boxplot for monetary_value_30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The maximum value in frequency_7 looks like an extreme outlier, however the overall picture of all columns looks fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the extreme outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recency_7</th>\n",
       "      <th>frequency_7</th>\n",
       "      <th>monetary_value_7</th>\n",
       "      <th>monetary_value_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22445</th>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>870.2</td>\n",
       "      <td>869.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      recency_7  frequency_7  monetary_value_7  monetary_value_30\n",
       "22445         7           56             870.2              869.2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['frequency_7']>50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like a valid point, will not remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before model fit, we have to convert the categorical features into one-hot encoding representation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency_7</th>\n",
       "      <th>monetary_value_7</th>\n",
       "      <th>monetary_value_30</th>\n",
       "      <th>recency_7_1</th>\n",
       "      <th>recency_7_2</th>\n",
       "      <th>recency_7_3</th>\n",
       "      <th>recency_7_4</th>\n",
       "      <th>recency_7_5</th>\n",
       "      <th>recency_7_6</th>\n",
       "      <th>recency_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72753</th>\n",
       "      <td>2</td>\n",
       "      <td>32.7</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72754</th>\n",
       "      <td>2</td>\n",
       "      <td>58.6</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72755</th>\n",
       "      <td>6</td>\n",
       "      <td>89.9</td>\n",
       "      <td>89.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72756</th>\n",
       "      <td>1</td>\n",
       "      <td>25.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72757</th>\n",
       "      <td>1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequency_7  monetary_value_7  monetary_value_30  recency_7_1  \\\n",
       "72753            2              32.7               32.7            0   \n",
       "72754            2              58.6               58.6            1   \n",
       "72755            6              89.9               89.9            0   \n",
       "72756            1              25.5               25.5            1   \n",
       "72757            1              18.8               18.8            1   \n",
       "\n",
       "       recency_7_2  recency_7_3  recency_7_4  recency_7_5  recency_7_6  \\\n",
       "72753            0            0            1            0            0   \n",
       "72754            0            0            0            0            0   \n",
       "72755            1            0            0            0            0   \n",
       "72756            0            0            0            0            0   \n",
       "72757            0            0            0            0            0   \n",
       "\n",
       "       recency_7_7  \n",
       "72753            0  \n",
       "72754            0  \n",
       "72755            0  \n",
       "72756            0  \n",
       "72757            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_hot_encoder(df):\n",
    "    columns_to_encode = []\n",
    "    def to_hot_encoder(df, column_to_remove):       \n",
    "        df = pd.concat([df, pd.get_dummies(df[column_to_remove], prefix=column_to_remove, drop_first=False)],axis=1)\n",
    "        df = df.drop([column_to_remove], axis=1)\n",
    "        return df\n",
    "\n",
    "    for col in df.columns:\n",
    "        if \"category\" in df.dtypes[col].name:\n",
    "            columns_to_encode.append(col)\n",
    "            \n",
    "    for column in columns_to_encode:\n",
    "        df = to_hot_encoder(df, column)\n",
    "    return df\n",
    "\n",
    "data_one_hot = convert_hot_encoder(data)\n",
    "\n",
    "\n",
    "display(data_one_hot.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to training, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train_one_hot, data_test_one_hot =\\\n",
    "train_test_split(data_one_hot, test_size=0.2)\n",
    "data_train_one_hot, data_val_one_hot =\\\n",
    "train_test_split(data_train_one_hot, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train_one_hot[['monetary_value_30']].to_numpy().flatten()\n",
    "x_train = data_train_one_hot.drop(['monetary_value_30'], axis=1).to_numpy()\n",
    "\n",
    "y_val = data_val_one_hot[['monetary_value_30']].to_numpy().flatten()\n",
    "x_val = data_val_one_hot.drop(['monetary_value_30'], axis=1).to_numpy()\n",
    "\n",
    "y_test = data_test_one_hot[['monetary_value_30']].to_numpy().flatten()\n",
    "x_test = data_test_one_hot.drop(['monetary_value_30'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize features using MinMaxScaler from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit and transform the data\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_val_scaled = scaler.transform(x_val)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "pickle.dump(scaler, open('fitted_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14552, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now train a neural network for the regression task (predicting \"monetary_value_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (None, 9). Output shape: (None, 500)\n",
      "Input shape: (None, 500). Output shape: (None, 300)\n",
      "Input shape: (None, 300). Output shape: (None, 200)\n",
      "Input shape: (None, 200). Output shape: (None, 50)\n",
      "Input shape: (None, 50). Output shape: (None, 1)\n",
      "Epoch 1/500\n",
      "44/44 [==============================] - 9s 17ms/step - loss: 5846.5591 - R2_coeff_determination: -0.3141 - val_loss: 3944.3281 - val_R2_coeff_determination: 0.1853\n",
      "Epoch 2/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 3624.4720 - R2_coeff_determination: 0.1855 - val_loss: 3626.3594 - val_R2_coeff_determination: 0.2498\n",
      "Epoch 3/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 3292.8786 - R2_coeff_determination: 0.2750 - val_loss: 2594.4475 - val_R2_coeff_determination: 0.4516\n",
      "Epoch 4/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 2177.6905 - R2_coeff_determination: 0.5138 - val_loss: 1967.1461 - val_R2_coeff_determination: 0.5739\n",
      "Epoch 5/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1859.1448 - R2_coeff_determination: 0.5864 - val_loss: 1942.6946 - val_R2_coeff_determination: 0.5805\n",
      "Epoch 6/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1725.5708 - R2_coeff_determination: 0.5909 - val_loss: 1863.2911 - val_R2_coeff_determination: 0.5968\n",
      "Epoch 7/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1950.8415 - R2_coeff_determination: 0.5945 - val_loss: 1882.6353 - val_R2_coeff_determination: 0.5937\n",
      "Epoch 8/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1828.3752 - R2_coeff_determination: 0.6107 - val_loss: 1848.8849 - val_R2_coeff_determination: 0.6004\n",
      "Epoch 9/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1732.8149 - R2_coeff_determination: 0.6044 - val_loss: 1851.3628 - val_R2_coeff_determination: 0.5997\n",
      "Epoch 10/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1882.4051 - R2_coeff_determination: 0.6082 - val_loss: 1845.6415 - val_R2_coeff_determination: 0.6015\n",
      "Epoch 11/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1682.8428 - R2_coeff_determination: 0.6111 - val_loss: 1860.3676 - val_R2_coeff_determination: 0.5978\n",
      "Epoch 12/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 2101.7909 - R2_coeff_determination: 0.5879 - val_loss: 1834.9969 - val_R2_coeff_determination: 0.6040\n",
      "Epoch 13/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1735.3886 - R2_coeff_determination: 0.6196 - val_loss: 1834.9048 - val_R2_coeff_determination: 0.6034\n",
      "Epoch 14/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1893.5569 - R2_coeff_determination: 0.6099 - val_loss: 1845.7643 - val_R2_coeff_determination: 0.6009\n",
      "Epoch 15/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1953.6462 - R2_coeff_determination: 0.5983 - val_loss: 1824.2799 - val_R2_coeff_determination: 0.6061\n",
      "Epoch 16/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1909.2457 - R2_coeff_determination: 0.6199 - val_loss: 1828.7908 - val_R2_coeff_determination: 0.6042\n",
      "Epoch 17/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1807.5374 - R2_coeff_determination: 0.6194 - val_loss: 1801.5011 - val_R2_coeff_determination: 0.6102\n",
      "Epoch 18/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1629.6822 - R2_coeff_determination: 0.6414 - val_loss: 1831.1984 - val_R2_coeff_determination: 0.6025\n",
      "Epoch 19/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1799.0412 - R2_coeff_determination: 0.6145 - val_loss: 1801.0825 - val_R2_coeff_determination: 0.6100\n",
      "Epoch 20/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1768.2895 - R2_coeff_determination: 0.6075 - val_loss: 1809.2815 - val_R2_coeff_determination: 0.6071\n",
      "Epoch 21/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1740.7162 - R2_coeff_determination: 0.6122 - val_loss: 1807.4399 - val_R2_coeff_determination: 0.6070\n",
      "Epoch 22/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1900.2547 - R2_coeff_determination: 0.6109 - val_loss: 1795.4661 - val_R2_coeff_determination: 0.6108\n",
      "Epoch 23/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1793.5875 - R2_coeff_determination: 0.6138 - val_loss: 1795.5630 - val_R2_coeff_determination: 0.6108\n",
      "Epoch 24/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1776.9024 - R2_coeff_determination: 0.6088 - val_loss: 1849.6975 - val_R2_coeff_determination: 0.5999\n",
      "Epoch 25/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1759.4082 - R2_coeff_determination: 0.6314 - val_loss: 1795.6912 - val_R2_coeff_determination: 0.6108\n",
      "Epoch 26/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1899.4201 - R2_coeff_determination: 0.6023 - val_loss: 1830.5577 - val_R2_coeff_determination: 0.6028\n",
      "Epoch 27/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1576.7763 - R2_coeff_determination: 0.6438 - val_loss: 1803.4846 - val_R2_coeff_determination: 0.6077\n",
      "Epoch 28/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1689.3196 - R2_coeff_determination: 0.6282 - val_loss: 1843.7621 - val_R2_coeff_determination: 0.5999\n",
      "Epoch 29/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1761.9855 - R2_coeff_determination: 0.6183 - val_loss: 1814.2086 - val_R2_coeff_determination: 0.6060\n",
      "Epoch 30/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1592.8726 - R2_coeff_determination: 0.6378 - val_loss: 1856.1683 - val_R2_coeff_determination: 0.5976\n",
      "Epoch 31/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1809.8419 - R2_coeff_determination: 0.6126 - val_loss: 1818.2449 - val_R2_coeff_determination: 0.6058\n",
      "Epoch 32/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1784.1813 - R2_coeff_determination: 0.6136 - val_loss: 1789.9816 - val_R2_coeff_determination: 0.6117\n",
      "Epoch 33/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1878.7758 - R2_coeff_determination: 0.6323 - val_loss: 1819.8920 - val_R2_coeff_determination: 0.6058\n",
      "Epoch 34/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1787.2702 - R2_coeff_determination: 0.6276 - val_loss: 1820.8479 - val_R2_coeff_determination: 0.6055\n",
      "Epoch 35/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1591.7075 - R2_coeff_determination: 0.6302 - val_loss: 1810.7312 - val_R2_coeff_determination: 0.6071\n",
      "Epoch 36/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1598.4257 - R2_coeff_determination: 0.6252 - val_loss: 1813.4166 - val_R2_coeff_determination: 0.6064\n",
      "Epoch 37/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1734.2641 - R2_coeff_determination: 0.6314 - val_loss: 1822.4719 - val_R2_coeff_determination: 0.6060\n",
      "Epoch 38/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1656.9594 - R2_coeff_determination: 0.6461 - val_loss: 1787.9452 - val_R2_coeff_determination: 0.6119\n",
      "Epoch 39/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1666.3897 - R2_coeff_determination: 0.5990 - val_loss: 1817.4854 - val_R2_coeff_determination: 0.6047\n",
      "Epoch 40/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1732.5941 - R2_coeff_determination: 0.6357 - val_loss: 1820.3997 - val_R2_coeff_determination: 0.6045\n",
      "Epoch 41/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1925.5483 - R2_coeff_determination: 0.6103 - val_loss: 1818.1198 - val_R2_coeff_determination: 0.6061\n",
      "Epoch 42/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1796.0248 - R2_coeff_determination: 0.5999 - val_loss: 1795.4910 - val_R2_coeff_determination: 0.6102\n",
      "Epoch 43/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1737.6251 - R2_coeff_determination: 0.6213 - val_loss: 1801.2655 - val_R2_coeff_determination: 0.6097\n",
      "Epoch 44/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1735.3841 - R2_coeff_determination: 0.6034 - val_loss: 1846.3596 - val_R2_coeff_determination: 0.6002\n",
      "Epoch 45/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1759.4262 - R2_coeff_determination: 0.6167 - val_loss: 1813.6395 - val_R2_coeff_determination: 0.6055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1663.8135 - R2_coeff_determination: 0.6506 - val_loss: 1812.4269 - val_R2_coeff_determination: 0.6068\n",
      "Epoch 47/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1934.4258 - R2_coeff_determination: 0.6119 - val_loss: 1804.1066 - val_R2_coeff_determination: 0.6075\n",
      "Epoch 48/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1753.7369 - R2_coeff_determination: 0.6065 - val_loss: 1815.1967 - val_R2_coeff_determination: 0.6048\n",
      "Epoch 49/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1793.5302 - R2_coeff_determination: 0.6302 - val_loss: 1807.4867 - val_R2_coeff_determination: 0.6090\n",
      "Epoch 50/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1764.0781 - R2_coeff_determination: 0.6172 - val_loss: 1843.7411 - val_R2_coeff_determination: 0.5990\n",
      "Epoch 51/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1692.1070 - R2_coeff_determination: 0.6248 - val_loss: 1807.5510 - val_R2_coeff_determination: 0.6084\n",
      "Epoch 52/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1672.9672 - R2_coeff_determination: 0.6160 - val_loss: 1808.3268 - val_R2_coeff_determination: 0.6085\n",
      "Epoch 53/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1750.7304 - R2_coeff_determination: 0.6263 - val_loss: 1810.9603 - val_R2_coeff_determination: 0.6077\n",
      "Epoch 54/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1751.5793 - R2_coeff_determination: 0.6008 - val_loss: 1810.3672 - val_R2_coeff_determination: 0.6079\n",
      "Epoch 55/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1651.7236 - R2_coeff_determination: 0.6137 - val_loss: 1816.6387 - val_R2_coeff_determination: 0.6049\n",
      "Epoch 56/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1814.6271 - R2_coeff_determination: 0.6270 - val_loss: 1830.0352 - val_R2_coeff_determination: 0.6026\n",
      "Epoch 57/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1806.9505 - R2_coeff_determination: 0.6142 - val_loss: 1831.5376 - val_R2_coeff_determination: 0.6026\n",
      "Epoch 58/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1777.1873 - R2_coeff_determination: 0.6284 - val_loss: 1798.7179 - val_R2_coeff_determination: 0.6101\n",
      "Epoch 59/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1800.1143 - R2_coeff_determination: 0.6260 - val_loss: 1815.5785 - val_R2_coeff_determination: 0.6056\n",
      "Epoch 60/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1774.2337 - R2_coeff_determination: 0.6271 - val_loss: 1802.1207 - val_R2_coeff_determination: 0.6088\n",
      "Epoch 61/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1857.4808 - R2_coeff_determination: 0.6125 - val_loss: 1811.4542 - val_R2_coeff_determination: 0.6081\n",
      "Epoch 62/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1678.7665 - R2_coeff_determination: 0.6046 - val_loss: 1814.5365 - val_R2_coeff_determination: 0.6067\n",
      "Epoch 63/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1951.2849 - R2_coeff_determination: 0.6129 - val_loss: 1837.7479 - val_R2_coeff_determination: 0.5994\n",
      "Epoch 64/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1732.7868 - R2_coeff_determination: 0.6218 - val_loss: 1823.2181 - val_R2_coeff_determination: 0.6038\n",
      "Epoch 65/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1847.0941 - R2_coeff_determination: 0.6320 - val_loss: 1830.8102 - val_R2_coeff_determination: 0.6042\n",
      "Epoch 66/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1616.4941 - R2_coeff_determination: 0.6277 - val_loss: 1818.8408 - val_R2_coeff_determination: 0.6056\n",
      "Epoch 67/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1896.5176 - R2_coeff_determination: 0.6112 - val_loss: 1815.9779 - val_R2_coeff_determination: 0.6066\n",
      "Epoch 68/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1699.6857 - R2_coeff_determination: 0.6408 - val_loss: 1824.5317 - val_R2_coeff_determination: 0.6043\n",
      "Epoch 69/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1743.7560 - R2_coeff_determination: 0.6358 - val_loss: 1807.9247 - val_R2_coeff_determination: 0.6078\n",
      "Epoch 70/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1793.1383 - R2_coeff_determination: 0.6245 - val_loss: 1829.0592 - val_R2_coeff_determination: 0.6013\n",
      "Epoch 71/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1815.4926 - R2_coeff_determination: 0.6173 - val_loss: 1820.7939 - val_R2_coeff_determination: 0.6035\n",
      "Epoch 72/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1804.5830 - R2_coeff_determination: 0.6131 - val_loss: 1808.6212 - val_R2_coeff_determination: 0.6070\n",
      "Epoch 73/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1853.5088 - R2_coeff_determination: 0.5808 - val_loss: 1807.8409 - val_R2_coeff_determination: 0.6078\n",
      "Epoch 74/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1728.9726 - R2_coeff_determination: 0.6239 - val_loss: 1808.7717 - val_R2_coeff_determination: 0.6075\n",
      "Epoch 75/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1671.3856 - R2_coeff_determination: 0.6232 - val_loss: 1826.5112 - val_R2_coeff_determination: 0.6024\n",
      "Epoch 76/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1568.4476 - R2_coeff_determination: 0.6386 - val_loss: 1848.8737 - val_R2_coeff_determination: 0.5966\n",
      "Epoch 77/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1836.8548 - R2_coeff_determination: 0.6196 - val_loss: 1833.8151 - val_R2_coeff_determination: 0.6013\n",
      "Epoch 78/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1662.1581 - R2_coeff_determination: 0.6112 - val_loss: 1812.5188 - val_R2_coeff_determination: 0.6056\n",
      "Epoch 79/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1857.6428 - R2_coeff_determination: 0.6250 - val_loss: 1834.1396 - val_R2_coeff_determination: 0.6027\n",
      "Epoch 80/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1716.6225 - R2_coeff_determination: 0.6245 - val_loss: 1812.5121 - val_R2_coeff_determination: 0.6078\n",
      "Epoch 81/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1653.7292 - R2_coeff_determination: 0.6431 - val_loss: 1805.9210 - val_R2_coeff_determination: 0.6087\n",
      "Epoch 82/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1845.6075 - R2_coeff_determination: 0.5904 - val_loss: 1809.0250 - val_R2_coeff_determination: 0.6074\n",
      "Epoch 83/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1675.1680 - R2_coeff_determination: 0.6238 - val_loss: 1820.0304 - val_R2_coeff_determination: 0.6042\n",
      "Epoch 84/500\n",
      "44/44 [==============================] - ETA: 0s - loss: 1916.0854 - R2_coeff_determination: 0.611 - 0s 10ms/step - loss: 1898.2967 - R2_coeff_determination: 0.6123 - val_loss: 1805.2742 - val_R2_coeff_determination: 0.6088\n",
      "Epoch 85/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1568.9458 - R2_coeff_determination: 0.6415 - val_loss: 1822.6229 - val_R2_coeff_determination: 0.6039\n",
      "Epoch 86/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1759.3965 - R2_coeff_determination: 0.6218 - val_loss: 1839.3027 - val_R2_coeff_determination: 0.5990\n",
      "Epoch 87/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 1819.3476 - R2_coeff_determination: 0.6126 - val_loss: 1823.7667 - val_R2_coeff_determination: 0.6034\n",
      "Epoch 88/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1733.0325 - R2_coeff_determination: 0.6006 - val_loss: 1818.8842 - val_R2_coeff_determination: 0.6039\n",
      "Epoch 89/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1687.0334 - R2_coeff_determination: 0.6334 - val_loss: 1819.3103 - val_R2_coeff_determination: 0.6040\n",
      "Epoch 90/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1907.5697 - R2_coeff_determination: 0.6220 - val_loss: 1819.1084 - val_R2_coeff_determination: 0.6052\n",
      "Epoch 91/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1726.7343 - R2_coeff_determination: 0.6350 - val_loss: 1852.4399 - val_R2_coeff_determination: 0.5967\n",
      "Epoch 92/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 10ms/step - loss: 1646.0773 - R2_coeff_determination: 0.6301 - val_loss: 1842.0640 - val_R2_coeff_determination: 0.6005\n",
      "Epoch 93/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1842.3235 - R2_coeff_determination: 0.6208 - val_loss: 1867.9542 - val_R2_coeff_determination: 0.5961\n",
      "Epoch 94/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1863.7071 - R2_coeff_determination: 0.6343 - val_loss: 1810.4913 - val_R2_coeff_determination: 0.6078\n",
      "Epoch 95/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1764.3420 - R2_coeff_determination: 0.6321 - val_loss: 1815.2506 - val_R2_coeff_determination: 0.6072\n",
      "Epoch 96/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1775.9494 - R2_coeff_determination: 0.6272 - val_loss: 1827.0839 - val_R2_coeff_determination: 0.6048\n",
      "Epoch 97/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1665.2689 - R2_coeff_determination: 0.6306 - val_loss: 1813.6243 - val_R2_coeff_determination: 0.6065\n",
      "Epoch 98/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1659.9291 - R2_coeff_determination: 0.6137 - val_loss: 1818.7787 - val_R2_coeff_determination: 0.6068\n",
      "Epoch 99/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1679.7723 - R2_coeff_determination: 0.6424 - val_loss: 1820.4658 - val_R2_coeff_determination: 0.6067\n",
      "Epoch 100/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1886.1071 - R2_coeff_determination: 0.6289 - val_loss: 1824.1859 - val_R2_coeff_determination: 0.6055\n",
      "Epoch 101/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1801.6867 - R2_coeff_determination: 0.6269 - val_loss: 1830.3994 - val_R2_coeff_determination: 0.6045\n",
      "Epoch 102/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1826.7885 - R2_coeff_determination: 0.6256 - val_loss: 1809.0188 - val_R2_coeff_determination: 0.6081\n",
      "Epoch 103/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1763.7955 - R2_coeff_determination: 0.6244 - val_loss: 1811.3646 - val_R2_coeff_determination: 0.6064\n",
      "Epoch 104/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1852.3106 - R2_coeff_determination: 0.6070 - val_loss: 1822.5336 - val_R2_coeff_determination: 0.6042\n",
      "Epoch 105/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1731.4033 - R2_coeff_determination: 0.6226 - val_loss: 1811.2919 - val_R2_coeff_determination: 0.6070\n",
      "Epoch 106/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1873.3533 - R2_coeff_determination: 0.6348 - val_loss: 1843.6027 - val_R2_coeff_determination: 0.5991\n",
      "Epoch 107/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1833.5987 - R2_coeff_determination: 0.6232 - val_loss: 1839.2728 - val_R2_coeff_determination: 0.6030\n",
      "Epoch 108/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 1542.6361 - R2_coeff_determination: 0.6335 - val_loss: 1804.2589 - val_R2_coeff_determination: 0.6080\n",
      "Epoch 109/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1881.8697 - R2_coeff_determination: 0.5958 - val_loss: 1807.5507 - val_R2_coeff_determination: 0.6082\n",
      "Epoch 110/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1698.3376 - R2_coeff_determination: 0.6275 - val_loss: 1823.3177 - val_R2_coeff_determination: 0.6057\n",
      "Epoch 111/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1643.7872 - R2_coeff_determination: 0.6247 - val_loss: 1821.3097 - val_R2_coeff_determination: 0.6034\n",
      "Epoch 112/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1752.5900 - R2_coeff_determination: 0.6097 - val_loss: 1855.4094 - val_R2_coeff_determination: 0.5949\n",
      "Epoch 113/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1720.6458 - R2_coeff_determination: 0.6328 - val_loss: 1844.6868 - val_R2_coeff_determination: 0.5984\n",
      "Epoch 114/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1783.1333 - R2_coeff_determination: 0.6056 - val_loss: 1826.5784 - val_R2_coeff_determination: 0.6031\n",
      "Epoch 115/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1709.9018 - R2_coeff_determination: 0.6083 - val_loss: 1812.7883 - val_R2_coeff_determination: 0.6062\n",
      "Epoch 116/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1681.8504 - R2_coeff_determination: 0.6286 - val_loss: 1816.4771 - val_R2_coeff_determination: 0.6064\n",
      "Epoch 117/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1707.3187 - R2_coeff_determination: 0.6341 - val_loss: 1827.5585 - val_R2_coeff_determination: 0.6034\n",
      "Epoch 118/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 2027.2398 - R2_coeff_determination: 0.5896 - val_loss: 1828.7402 - val_R2_coeff_determination: 0.6048\n",
      "Epoch 119/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1666.0438 - R2_coeff_determination: 0.6156 - val_loss: 1810.6401 - val_R2_coeff_determination: 0.6063\n",
      "Epoch 120/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1588.8380 - R2_coeff_determination: 0.6371 - val_loss: 1808.4545 - val_R2_coeff_determination: 0.6070\n",
      "Epoch 121/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1692.0924 - R2_coeff_determination: 0.6302 - val_loss: 1833.6121 - val_R2_coeff_determination: 0.6035\n",
      "Epoch 122/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1681.2891 - R2_coeff_determination: 0.6251 - val_loss: 1851.1936 - val_R2_coeff_determination: 0.5982\n",
      "Epoch 123/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1847.9572 - R2_coeff_determination: 0.5939 - val_loss: 1828.3702 - val_R2_coeff_determination: 0.6047\n",
      "Epoch 124/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1711.9481 - R2_coeff_determination: 0.6308 - val_loss: 1838.4550 - val_R2_coeff_determination: 0.6011\n",
      "Epoch 125/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1739.2109 - R2_coeff_determination: 0.6474 - val_loss: 1820.8252 - val_R2_coeff_determination: 0.6057\n",
      "Epoch 126/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1688.0383 - R2_coeff_determination: 0.6207 - val_loss: 1828.0607 - val_R2_coeff_determination: 0.6039\n",
      "Epoch 127/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1838.2446 - R2_coeff_determination: 0.6317 - val_loss: 1821.2946 - val_R2_coeff_determination: 0.6065\n",
      "Epoch 128/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1502.8389 - R2_coeff_determination: 0.6280 - val_loss: 1851.8730 - val_R2_coeff_determination: 0.5989\n",
      "Epoch 129/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1583.2311 - R2_coeff_determination: 0.6270 - val_loss: 1876.0558 - val_R2_coeff_determination: 0.5903\n",
      "Epoch 130/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1588.4679 - R2_coeff_determination: 0.6470 - val_loss: 1844.1237 - val_R2_coeff_determination: 0.5977\n",
      "Epoch 131/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1754.5395 - R2_coeff_determination: 0.6257 - val_loss: 1823.9137 - val_R2_coeff_determination: 0.6041\n",
      "Epoch 132/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1774.8322 - R2_coeff_determination: 0.6297 - val_loss: 1841.5667 - val_R2_coeff_determination: 0.6018\n",
      "Epoch 133/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1714.5908 - R2_coeff_determination: 0.6244 - val_loss: 1816.1442 - val_R2_coeff_determination: 0.6068\n",
      "Epoch 134/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1693.5110 - R2_coeff_determination: 0.6502 - val_loss: 1810.9817 - val_R2_coeff_determination: 0.6079\n",
      "Epoch 135/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1728.3766 - R2_coeff_determination: 0.6241 - val_loss: 1828.7247 - val_R2_coeff_determination: 0.6035\n",
      "Epoch 136/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1781.7299 - R2_coeff_determination: 0.6227 - val_loss: 1823.3568 - val_R2_coeff_determination: 0.6046\n",
      "Epoch 137/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1817.8215 - R2_coeff_determination: 0.6122 - val_loss: 1813.6700 - val_R2_coeff_determination: 0.6064\n",
      "Epoch 138/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1621.1232 - R2_coeff_determination: 0.6310 - val_loss: 1821.5952 - val_R2_coeff_determination: 0.6049\n",
      "Epoch 139/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1763.3642 - R2_coeff_determination: 0.6257 - val_loss: 1830.2935 - val_R2_coeff_determination: 0.6017\n",
      "Epoch 140/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1758.6916 - R2_coeff_determination: 0.6201 - val_loss: 1811.0492 - val_R2_coeff_determination: 0.6069\n",
      "Epoch 141/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1677.0774 - R2_coeff_determination: 0.6355 - val_loss: 1815.2823 - val_R2_coeff_determination: 0.6055\n",
      "Epoch 142/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1707.8333 - R2_coeff_determination: 0.6283 - val_loss: 1817.3320 - val_R2_coeff_determination: 0.6063\n",
      "Epoch 143/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1648.2530 - R2_coeff_determination: 0.6277 - val_loss: 1826.7039 - val_R2_coeff_determination: 0.6030\n",
      "Epoch 144/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1744.2054 - R2_coeff_determination: 0.6133 - val_loss: 1845.7944 - val_R2_coeff_determination: 0.6011\n",
      "Epoch 145/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1546.6219 - R2_coeff_determination: 0.6396 - val_loss: 1813.1589 - val_R2_coeff_determination: 0.6063\n",
      "Epoch 146/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1759.1520 - R2_coeff_determination: 0.6127 - val_loss: 1827.4169 - val_R2_coeff_determination: 0.6037\n",
      "Epoch 147/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1601.9744 - R2_coeff_determination: 0.6256 - val_loss: 1854.3461 - val_R2_coeff_determination: 0.5952\n",
      "Epoch 148/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1602.5831 - R2_coeff_determination: 0.6331 - val_loss: 1863.7469 - val_R2_coeff_determination: 0.5944\n",
      "Epoch 149/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1806.4944 - R2_coeff_determination: 0.6104 - val_loss: 1826.3651 - val_R2_coeff_determination: 0.6043\n",
      "Epoch 150/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1799.8017 - R2_coeff_determination: 0.6285 - val_loss: 1838.5034 - val_R2_coeff_determination: 0.6016\n",
      "Epoch 151/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1742.6182 - R2_coeff_determination: 0.6090 - val_loss: 1815.1349 - val_R2_coeff_determination: 0.6062\n",
      "Epoch 152/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1517.9197 - R2_coeff_determination: 0.6264 - val_loss: 1860.4276 - val_R2_coeff_determination: 0.5945\n",
      "Epoch 153/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1583.5784 - R2_coeff_determination: 0.6242 - val_loss: 1830.9115 - val_R2_coeff_determination: 0.6026\n",
      "Epoch 154/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1643.8894 - R2_coeff_determination: 0.6133 - val_loss: 1829.4022 - val_R2_coeff_determination: 0.6033\n",
      "Epoch 155/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1744.1201 - R2_coeff_determination: 0.6183 - val_loss: 1820.8517 - val_R2_coeff_determination: 0.6063\n",
      "Epoch 156/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1890.1884 - R2_coeff_determination: 0.6321 - val_loss: 1827.2303 - val_R2_coeff_determination: 0.6026\n",
      "Epoch 157/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1726.2206 - R2_coeff_determination: 0.6145 - val_loss: 1840.6760 - val_R2_coeff_determination: 0.6007\n",
      "Epoch 158/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1701.8949 - R2_coeff_determination: 0.6306 - val_loss: 1821.8910 - val_R2_coeff_determination: 0.6057\n",
      "Epoch 159/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1579.9840 - R2_coeff_determination: 0.6329 - val_loss: 1832.5900 - val_R2_coeff_determination: 0.6019\n",
      "Epoch 160/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1831.6839 - R2_coeff_determination: 0.6170 - val_loss: 1831.6057 - val_R2_coeff_determination: 0.6028\n",
      "Epoch 161/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1761.1386 - R2_coeff_determination: 0.6342 - val_loss: 1815.1367 - val_R2_coeff_determination: 0.6067\n",
      "Epoch 162/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1783.8919 - R2_coeff_determination: 0.6165 - val_loss: 1819.1615 - val_R2_coeff_determination: 0.6049\n",
      "Epoch 163/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1919.1812 - R2_coeff_determination: 0.6222 - val_loss: 1828.3301 - val_R2_coeff_determination: 0.6029\n",
      "Epoch 164/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1695.3926 - R2_coeff_determination: 0.6322 - val_loss: 1825.3762 - val_R2_coeff_determination: 0.6050\n",
      "Epoch 165/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1675.1601 - R2_coeff_determination: 0.6272 - val_loss: 1819.7223 - val_R2_coeff_determination: 0.6047\n",
      "Epoch 166/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1711.1998 - R2_coeff_determination: 0.6373 - val_loss: 1837.7625 - val_R2_coeff_determination: 0.6010\n",
      "Epoch 167/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1772.1746 - R2_coeff_determination: 0.6175 - val_loss: 1818.8264 - val_R2_coeff_determination: 0.6060\n",
      "Epoch 168/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1654.2978 - R2_coeff_determination: 0.6225 - val_loss: 1837.1448 - val_R2_coeff_determination: 0.6026\n",
      "Epoch 169/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 1800.5929 - R2_coeff_determination: 0.6054 - val_loss: 1818.0491 - val_R2_coeff_determination: 0.6062\n",
      "Epoch 170/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1613.4828 - R2_coeff_determination: 0.6393 - val_loss: 1818.5488 - val_R2_coeff_determination: 0.6052\n",
      "Epoch 171/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1864.5119 - R2_coeff_determination: 0.6294 - val_loss: 1841.9495 - val_R2_coeff_determination: 0.6012\n",
      "Epoch 172/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1698.1436 - R2_coeff_determination: 0.6209 - val_loss: 1830.0646 - val_R2_coeff_determination: 0.6021\n",
      "Epoch 173/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1583.2483 - R2_coeff_determination: 0.6464 - val_loss: 1819.4902 - val_R2_coeff_determination: 0.6048\n",
      "Epoch 174/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1594.1136 - R2_coeff_determination: 0.6120 - val_loss: 1836.8577 - val_R2_coeff_determination: 0.5996\n",
      "Epoch 175/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1582.1876 - R2_coeff_determination: 0.6230 - val_loss: 1834.8810 - val_R2_coeff_determination: 0.6017\n",
      "Epoch 176/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1560.6862 - R2_coeff_determination: 0.6454 - val_loss: 1828.4199 - val_R2_coeff_determination: 0.6038\n",
      "Epoch 177/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1982.8006 - R2_coeff_determination: 0.6110 - val_loss: 1837.0399 - val_R2_coeff_determination: 0.6022\n",
      "Epoch 178/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1841.6081 - R2_coeff_determination: 0.6185 - val_loss: 1832.0558 - val_R2_coeff_determination: 0.6046\n",
      "Epoch 179/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1632.4247 - R2_coeff_determination: 0.6263 - val_loss: 1839.2927 - val_R2_coeff_determination: 0.6004\n",
      "Epoch 180/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1650.4338 - R2_coeff_determination: 0.6482 - val_loss: 1816.8965 - val_R2_coeff_determination: 0.6071\n",
      "Epoch 181/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1661.3475 - R2_coeff_determination: 0.6261 - val_loss: 1835.7250 - val_R2_coeff_determination: 0.6004\n",
      "Epoch 182/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1754.9103 - R2_coeff_determination: 0.6140 - val_loss: 1836.7275 - val_R2_coeff_determination: 0.5999\n",
      "Epoch 183/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1728.7911 - R2_coeff_determination: 0.6227 - val_loss: 1877.9456 - val_R2_coeff_determination: 0.5909\n",
      "Epoch 184/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 10ms/step - loss: 1696.9585 - R2_coeff_determination: 0.6289 - val_loss: 1858.6439 - val_R2_coeff_determination: 0.5955\n",
      "Epoch 185/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1743.7877 - R2_coeff_determination: 0.6086 - val_loss: 1839.7955 - val_R2_coeff_determination: 0.6013\n",
      "Epoch 186/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1636.8335 - R2_coeff_determination: 0.6342 - val_loss: 1837.1230 - val_R2_coeff_determination: 0.6005\n",
      "Epoch 187/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1551.7424 - R2_coeff_determination: 0.6357 - val_loss: 1842.8417 - val_R2_coeff_determination: 0.5986\n",
      "Epoch 188/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 1687.0228 - R2_coeff_determination: 0.6138 - val_loss: 1897.8557 - val_R2_coeff_determination: 0.5913\n",
      "Epoch 189/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1620.6950 - R2_coeff_determination: 0.6251 - val_loss: 1844.3927 - val_R2_coeff_determination: 0.5983\n",
      "Epoch 190/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1682.9581 - R2_coeff_determination: 0.6274 - val_loss: 1833.9872 - val_R2_coeff_determination: 0.6028\n",
      "Epoch 191/500\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 1585.3118 - R2_coeff_determination: 0.6163 - val_loss: 1840.9872 - val_R2_coeff_determination: 0.6011\n",
      "Epoch 192/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1753.0965 - R2_coeff_determination: 0.6154 - val_loss: 1843.7172 - val_R2_coeff_determination: 0.6007\n",
      "Epoch 193/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1762.5999 - R2_coeff_determination: 0.6115 - val_loss: 1837.4600 - val_R2_coeff_determination: 0.6015\n",
      "Epoch 194/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1901.9651 - R2_coeff_determination: 0.6081 - val_loss: 1823.5380 - val_R2_coeff_determination: 0.6045\n",
      "Epoch 195/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1651.2777 - R2_coeff_determination: 0.6310 - val_loss: 1823.6012 - val_R2_coeff_determination: 0.6037\n",
      "Epoch 196/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1771.1967 - R2_coeff_determination: 0.6212 - val_loss: 1833.1506 - val_R2_coeff_determination: 0.6021\n",
      "Epoch 197/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1694.9322 - R2_coeff_determination: 0.6256 - val_loss: 1836.0408 - val_R2_coeff_determination: 0.6020\n",
      "Epoch 198/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1705.3757 - R2_coeff_determination: 0.6190 - val_loss: 1878.5073 - val_R2_coeff_determination: 0.5935\n",
      "Epoch 199/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1653.6578 - R2_coeff_determination: 0.6256 - val_loss: 1818.5001 - val_R2_coeff_determination: 0.6051\n",
      "Epoch 200/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1648.3951 - R2_coeff_determination: 0.6423 - val_loss: 1828.5992 - val_R2_coeff_determination: 0.6037\n",
      "Epoch 201/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1531.2184 - R2_coeff_determination: 0.6269 - val_loss: 1860.1504 - val_R2_coeff_determination: 0.5978\n",
      "Epoch 202/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1595.4250 - R2_coeff_determination: 0.6198 - val_loss: 1838.1652 - val_R2_coeff_determination: 0.6006\n",
      "Epoch 203/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1712.1411 - R2_coeff_determination: 0.6423 - val_loss: 1839.4939 - val_R2_coeff_determination: 0.5999\n",
      "Epoch 204/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1726.6708 - R2_coeff_determination: 0.6362 - val_loss: 1841.6423 - val_R2_coeff_determination: 0.6020\n",
      "Epoch 205/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1723.9795 - R2_coeff_determination: 0.6150 - val_loss: 1830.6646 - val_R2_coeff_determination: 0.6025\n",
      "Epoch 206/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1569.9869 - R2_coeff_determination: 0.6307 - val_loss: 1843.3167 - val_R2_coeff_determination: 0.5991\n",
      "Epoch 207/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1602.2220 - R2_coeff_determination: 0.6439 - val_loss: 1822.4789 - val_R2_coeff_determination: 0.6059\n",
      "Epoch 208/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1575.2961 - R2_coeff_determination: 0.6335 - val_loss: 1835.7241 - val_R2_coeff_determination: 0.6009\n",
      "Epoch 209/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1664.9005 - R2_coeff_determination: 0.6376 - val_loss: 1849.8461 - val_R2_coeff_determination: 0.5990\n",
      "Epoch 210/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1610.0120 - R2_coeff_determination: 0.6317 - val_loss: 1826.0144 - val_R2_coeff_determination: 0.6044\n",
      "Epoch 211/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1644.4507 - R2_coeff_determination: 0.6248 - val_loss: 1834.8734 - val_R2_coeff_determination: 0.6018\n",
      "Epoch 212/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1575.8802 - R2_coeff_determination: 0.6276 - val_loss: 1827.9390 - val_R2_coeff_determination: 0.6034\n",
      "Epoch 213/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1906.9777 - R2_coeff_determination: 0.6238 - val_loss: 1855.4758 - val_R2_coeff_determination: 0.5990\n",
      "Epoch 214/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1774.1365 - R2_coeff_determination: 0.6313 - val_loss: 1832.4478 - val_R2_coeff_determination: 0.6028\n",
      "Epoch 215/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1712.4092 - R2_coeff_determination: 0.6028 - val_loss: 1836.5643 - val_R2_coeff_determination: 0.6035\n",
      "Epoch 216/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1555.5630 - R2_coeff_determination: 0.6326 - val_loss: 1845.9249 - val_R2_coeff_determination: 0.5977\n",
      "Epoch 217/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1567.3554 - R2_coeff_determination: 0.6375 - val_loss: 1843.0851 - val_R2_coeff_determination: 0.6005\n",
      "Epoch 218/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1747.2664 - R2_coeff_determination: 0.6183 - val_loss: 1841.3672 - val_R2_coeff_determination: 0.6010\n",
      "Epoch 219/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1612.9428 - R2_coeff_determination: 0.6580 - val_loss: 1840.9080 - val_R2_coeff_determination: 0.6026\n",
      "Epoch 220/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1586.4520 - R2_coeff_determination: 0.6136 - val_loss: 1832.9031 - val_R2_coeff_determination: 0.6016\n",
      "Epoch 221/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1718.8825 - R2_coeff_determination: 0.6416 - val_loss: 1890.7653 - val_R2_coeff_determination: 0.5924\n",
      "Epoch 222/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1642.6493 - R2_coeff_determination: 0.6141 - val_loss: 1869.2478 - val_R2_coeff_determination: 0.5921\n",
      "Epoch 223/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1707.2723 - R2_coeff_determination: 0.6453 - val_loss: 1816.5735 - val_R2_coeff_determination: 0.6064\n",
      "Epoch 224/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1757.6565 - R2_coeff_determination: 0.6248 - val_loss: 1853.7919 - val_R2_coeff_determination: 0.6001\n",
      "Epoch 225/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1970.6078 - R2_coeff_determination: 0.5976 - val_loss: 1850.1038 - val_R2_coeff_determination: 0.5995\n",
      "Epoch 226/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1758.5201 - R2_coeff_determination: 0.5994 - val_loss: 1844.8416 - val_R2_coeff_determination: 0.5997\n",
      "Epoch 227/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1731.9445 - R2_coeff_determination: 0.6217 - val_loss: 1828.8671 - val_R2_coeff_determination: 0.6041\n",
      "Epoch 228/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1678.3214 - R2_coeff_determination: 0.6175 - val_loss: 1849.0674 - val_R2_coeff_determination: 0.6008\n",
      "Epoch 229/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1787.9017 - R2_coeff_determination: 0.6184 - val_loss: 1831.3184 - val_R2_coeff_determination: 0.6050\n",
      "Epoch 230/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1760.4945 - R2_coeff_determination: 0.6189 - val_loss: 1867.2373 - val_R2_coeff_determination: 0.5931\n",
      "Epoch 231/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1853.6598 - R2_coeff_determination: 0.6155 - val_loss: 1835.7469 - val_R2_coeff_determination: 0.6005\n",
      "Epoch 232/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1678.6677 - R2_coeff_determination: 0.6249 - val_loss: 1843.5626 - val_R2_coeff_determination: 0.5997\n",
      "Epoch 233/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1755.6700 - R2_coeff_determination: 0.6409 - val_loss: 1828.5974 - val_R2_coeff_determination: 0.6031\n",
      "Epoch 234/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1765.9774 - R2_coeff_determination: 0.6169 - val_loss: 1853.2201 - val_R2_coeff_determination: 0.5995\n",
      "Epoch 235/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1621.3683 - R2_coeff_determination: 0.6139 - val_loss: 1860.7137 - val_R2_coeff_determination: 0.5951\n",
      "Epoch 236/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1700.8761 - R2_coeff_determination: 0.6282 - val_loss: 1838.1167 - val_R2_coeff_determination: 0.6012\n",
      "Epoch 237/500\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1607.5409 - R2_coeff_determination: 0.6282 - val_loss: 1851.1455 - val_R2_coeff_determination: 0.6000\n",
      "Epoch 238/500\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1578.5692 - R2_coeff_determination: 0.6265 - val_loss: 1838.2357 - val_R2_coeff_determination: 0.6023\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00238: early stopping\n",
      "mean squared error and R2 score between predictions and actual values on testset are respectively 1547.27 and 0.6685 \n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback, ModelCheckpoint, TensorBoard, LearningRateScheduler, EarlyStopping\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def R2_coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred)) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(500, activation='relu', input_shape=(x_train_scaled.shape[1],)))\n",
    "model_nn.add(Dense(300, activation='relu'))\n",
    "model_nn.add(Dense(200, activation='relu'))\n",
    "model_nn.add(Dense(50, activation='relu'))\n",
    "model_nn.add(Dense(1))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\\\n",
    "                               patience=200, restore_best_weights=True)\n",
    "\n",
    "for layer in model_nn.layers:\n",
    "    print(\"Input shape: \"+str(layer.input_shape)+\". Output shape: \"+str(layer.output_shape))\n",
    "model_nn.compile(loss='mean_squared_error', optimizer='adam', metrics = [R2_coeff_determination])\n",
    "history =model_nn.fit(x_train_scaled, y_train, validation_data=(x_val_scaled, y_val),\n",
    "                epochs=500,\n",
    "                batch_size=1000,\n",
    "                shuffle=True,\n",
    "                verbose=1, callbacks = [early_stopping]).history\n",
    "\n",
    "predictions_test_nn = model_nn.predict(x_test_scaled).flatten()\n",
    "R2_score_nn = R2_coeff_determination(K.constant(y_test),predictions_test_nn).numpy()\n",
    "print(\"mean squared error and R2 score between predictions and actual values on testset are respectively {:.2f}\\\n",
    " and {:.4f} \".format(((y_test - predictions_test_nn)**2).mean(), R2_score_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So R^2 value on the testset is around 0.66. There is no much overfitting but there is a siginifcant underfitting that I couldn't combat using a deeper network. Probably because of there is only 3 features and it could be that they don't fully relate to the label we want to predict. Intuitevly the usage of the user over 30 days can be influenced by many things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just to try out different regressors fast using sklearn to see if they can do better, plus using cross-validaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "Ridge()\n",
      "HuberRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/Users/abdullahsalama/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_huber.py:296: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNetCV()\n",
      "DecisionTreeRegressor()\n",
      "ExtraTreesRegressor()\n",
      "GradientBoostingRegressor()\n",
      "RandomForestRegressor()\n",
      "BaggingRegressor()\n",
      "GradientBoostingRegressor()\n",
      "mean squared error and R2 score between predictions and actual values on testset are respectively 1529.76 and 0.6731 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, HuberRegressor, ElasticNetCV\n",
    "from sklearn.ensemble import BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "models = [LinearRegression(),\n",
    "          Ridge(),\n",
    "          HuberRegressor(),\n",
    "          ElasticNetCV(),\n",
    "          DecisionTreeRegressor(), \n",
    "          ExtraTreesRegressor(),\n",
    "          GradientBoostingRegressor(),\n",
    "          RandomForestRegressor(),\n",
    "          BaggingRegressor(),\n",
    "          GradientBoostingRegressor()]\n",
    "\n",
    "models_scores = pd.DataFrame(columns = ['Model', 'Score'])\n",
    "\n",
    "def test_algorithms(model):\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    predicted = model_selection.cross_val_score(model, x_train_scaled, y_train, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    score=abs(predicted.mean())\n",
    "    return score\n",
    "\n",
    "best_score=100000\n",
    "best_model_sk=[]\n",
    "for model in models:\n",
    "    print(model)\n",
    "    score=test_algorithms(model)\n",
    "    models_scores  = models_scores.append({'Model': model, 'Score': score}, ignore_index = True)\n",
    "    if abs(score)<best_score:\n",
    "        best_score=abs(score)\n",
    "        best_model_sk=model\n",
    "        \n",
    "best_model_sk.fit(x_train_scaled, y_train)\n",
    "predictions_test_sk = best_model_sk.predict(x_train_scaled).flatten()\n",
    "R2_score_sk = R2_coeff_determination(K.constant(y_train),predictions_test_sk).numpy()\n",
    "print(\"mean squared error and R2 score between predictions and actual values on testset are respectively {:.2f}\\\n",
    " and {:.4f} \".format(((y_train - predictions_test_sk)**2).mean(), R2_score_sk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, if the R2 score of the Neural Network (NN) model trained is better than the other regressor models, then save the NN model, otherwise save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if R2_score_nn > R2_score_sk:\n",
    "    pickle.dump(model_nn, open('trained_model.pkl', 'wb'))\n",
    "else:\n",
    "    pickle.dump(best_model_sk, open('trained_model.pkl', 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
